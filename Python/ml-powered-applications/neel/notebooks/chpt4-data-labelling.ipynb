{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Powered Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4\n",
    "\n",
    "Data exploration notebook to better understand the data.\n",
    "\n",
    "Objective\n",
    "- To label and identify trends\n",
    "\n",
    "Process\n",
    "- Generate summary statistics\n",
    "- Identifying differences in class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run script on a 3.6 environment - base36\n",
    "!pip install -U spacy\n",
    "!pip install -U umap-learn\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# intialization\n",
    "PATH_data = r\"C:\\Users\\nrosh\\Desktop\\Personal Coding Projects\\Python\\ml-powered-applications\\neel\\data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "\n",
    "1. Clustering\n",
    "    - Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters)\n",
    "    - Many clustering algorithms group data points by measuring the distance between points and assigning ones that are close to each other to the same cluster.\n",
    "    - The vast majority of datasets can be separated into clusters based on their features, labels, or a combination of both. Examining each cluster individually and the similarities and differences between clusters is a great way to identify structure in a dataset.\n",
    "    - Clustering algorithms work on vectors, so we can’t simply pass a set of sentences to a clustering algorithm. To get our data ready to be clustered, we will first need to vectorize it.\n",
    "\n",
    "2. Vectorization\n",
    "    - A process of converting a raw data set into a singular or multi-dimensional vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization techniques\n",
    "\n",
    "Clustering requires distances to be measured on the \"same\" scale.\n",
    "\n",
    "The approach for vectorizing/normalizing data depends on the structure and type of data being analysed.\n",
    "\n",
    "1. Tabular data\n",
    "    - Continuous features should be normalized to a common scale\n",
    "    - Categorical features such as colors can be converted to a one-hot encoding (binary transformations). This allows the distance between points to always remain the same.\n",
    "    \n",
    "2. Text data\n",
    "\n",
    "    - Bag Of Words (Tokenize sentences and count their observations by row)\n",
    "        - The simplest way to vectorize text is to use a count vector, which is the word equivalent of one-hot encoding.\n",
    "        - For each sentence, the number at each index represents the count of occurrences of the associated word in the given sentence.\n",
    "        -This method ignores the order of the words in a sentence\n",
    "        - scikit-learn TfidfVectorizer\n",
    "            - Produce a vector of tokenized words for count aggregation by row\n",
    "            - https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "    - Word2ec and fastText\n",
    "        - These vectorization techniques produce word vectors that attempt to learn a representation that captures similarities between concepts better than a TF-IDF encoding. \n",
    "        - They do this by learning which words tend to appear in similar contexts in large bodies of text such as Wikipedia.\n",
    "        - This approach is based on the distributional hypothesis, which claims that linguistic items with similar distributions have similar meanings.\n",
    "            - This is done by learning a vector for each word and training a model to predict a missing word in a sentence using the word vectors of words around it. \n",
    "            - The number of neighboring words to take into account is called the window size.\n",
    "    - Dimensionality Reduction\n",
    "        - Vectorized data are multi-dimensional and can't be visualized\n",
    "        - The goal is to use a method that reduces multidimensional data into a visual space whilst minimizing the data loss associated with dimensional reduction\n",
    "        - Techniques\n",
    "            - t-SNE\n",
    "            - UMAP\n",
    "        - These techniques are useful for to notice patterns in data on a very high level\n",
    "        - The goal is to use these methods to see whether there are regions of the data that can easily be seperated by a production model\n",
    "        - \n",
    "\n",
    "UMAP\n",
    "    - General purpose manifold learning and dimension reduction algorithm\n",
    "    \n",
    "    \n",
    "Once we have a vectorized representation of our unstructured data, we can use it for the purpose of data inspection/exploration or outcome predictions.\n",
    "\n",
    "1. Inspection\n",
    "        - Dimensionality Reduction\n",
    "             - Vectors produced from unstructured data often have more than one dimension. The dataset needs to be reduced in some way for us to visualize it on a two-dimensional plane.\n",
    "             - \n",
    "\n",
    "2. Prediction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling Strategy\n",
    "Feel free to update your vectorization strategy by adding any features you discover to help make your data representation as informative as possible, and go back to labeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"vectorization_strategy.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"vectorization_strategy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics Observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Are there distinct regions of post's title that can be classified into one or multiple labels?\n",
    "    \n",
    "Sources:\n",
    "- stackexchange: \n",
    "    - Data Schema: https://meta.stackexchange.com/questions/2677/database-schema-documentation-for-the-public-data-dump-and-sede\n",
    "    - Score: https://meta.stackexchange.com/questions/229255/what-is-the-score-of-a-post\n",
    "    - UMAP: https://umap-learn.readthedocs.io/en/latest/\n",
    "    \n",
    "- word2vec: https://code.google.com/archive/p/word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df(df, cols, **kwargs):\n",
    "\n",
    "    # rename and return a dataframe of those columns\n",
    "    # choose to export or not\n",
    "    \n",
    "    _df = df.loc[:, cols]\n",
    "    \n",
    "    # rename dict\n",
    "    if \"rename_dict\" in kwargs.keys() :\n",
    "        _df.rename(columns=kwargs[\"rename_dict\"], inplace=True)\n",
    "        print('- Columns renamed.')\n",
    "    \n",
    "    # export data\n",
    "    if kwargs[\"export_loc\"]:\n",
    "        \n",
    "        # handle data export\n",
    "        try:\n",
    "            \n",
    "            if \"export_name\" in kwargs.keys():\n",
    "                _location = kwargs[\"export_loc\"] + \"\\\\{}\".format(kwargs[\"export_name\"]) + \".csv\"\n",
    "                _df.to_csv(_location)\n",
    "                print(f\"\"\"- File exported to: {_location}\"\"\")\n",
    "            else:\n",
    "                _location = kwargs[\"export_loc\"]+\"\\\\adhoc_{}\".format(datetime.today().strftime(\"%m%d%y\"))+\".csv\"\n",
    "                _df.to_csv(_location)\n",
    "                print(f\"\"\"- File exported to: {_location}\"\"\")\n",
    "\n",
    "        except:\n",
    "            raise Exception(f\"\"\"export_loc must be of type str. Given: {type(kwargs[\"export_loc\"])}\"\"\")\n",
    "    \n",
    "    print('\\n')\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9935 entries, 0 to 9934\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   PostTypeId            9935 non-null   int64  \n",
      " 1   AcceptedAnswerId      5081 non-null   float64\n",
      " 2   ParentId              0 non-null      float64\n",
      " 3   AnswerCount           9935 non-null   float64\n",
      " 4   CommentCount          9935 non-null   int64  \n",
      " 5   FavoriteCount         4052 non-null   float64\n",
      " 6   LastActivityDate      9935 non-null   object \n",
      " 7   CreationDate          9935 non-null   object \n",
      " 8   ClosedDate            1294 non-null   object \n",
      " 9   LastEditDate          6222 non-null   object \n",
      " 10  Score                 9935 non-null   int64  \n",
      " 11  Title                 9935 non-null   object \n",
      " 12  body_text             9935 non-null   object \n",
      " 13  fe_tenure             9935 non-null   float64\n",
      " 14  fe_isclosed           9935 non-null   int64  \n",
      " 15  fe_isquestion         9935 non-null   int64  \n",
      " 16  fe_isanswer           9935 non-null   int64  \n",
      " 17  fe_isfavorited        9935 non-null   int64  \n",
      " 18  fe_wasedited          9935 non-null   int64  \n",
      " 19  fe_question_answered  9935 non-null   int64  \n",
      " 20  umap_x_Title          9935 non-null   float64\n",
      " 21  umap_y_Title          9935 non-null   float64\n",
      " 22  kmeans_cluster_Title  9935 non-null   int64  \n",
      "dtypes: float64(7), int64(10), object(6)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "df_orig = pd.read_csv(\n",
    "    PATH_data + \"\\\\labelling\\kmean_clusteral_predictions.csv\",\n",
    ")\n",
    "\n",
    "# copies\n",
    "df = df_orig.iloc[:, 1::].copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Strategy\n",
    "\n",
    "Goal: \n",
    "1. To produce features that describe each clusters uniquely \n",
    "2. To produce the results you would like it to produce\n",
    "\n",
    "Strategies:\n",
    "\n",
    "1. Update your vectorization strategy by adding any features you discover to help make your data representation as informative as possible, and go back to labeling.\n",
    "2. To speed up your labeling, leverage your prior analysis by labeling a few data points in each cluster and for each common value in your feature distribution.\n",
    "3. Use cluster visualizations to infer characteristics about each data point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>LastEditDate</th>\n",
       "      <th>...</th>\n",
       "      <th>fe_tenure</th>\n",
       "      <th>fe_isclosed</th>\n",
       "      <th>fe_isquestion</th>\n",
       "      <th>fe_isanswer</th>\n",
       "      <th>fe_isfavorited</th>\n",
       "      <th>fe_wasedited</th>\n",
       "      <th>fe_question_answered</th>\n",
       "      <th>umap_x_Title</th>\n",
       "      <th>umap_y_Title</th>\n",
       "      <th>kmeans_cluster_Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2019-03-31 20:10:59.657</td>\n",
       "      <td>2010-11-18 20:40:32.857</td>\n",
       "      <td>2019-09-09 15:44:30.727</td>\n",
       "      <td>2019-02-10 04:06:33.283</td>\n",
       "      <td>...</td>\n",
       "      <td>77184.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.863544</td>\n",
       "      <td>2.543220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-04-29 19:35:55.850</td>\n",
       "      <td>2010-11-18 20:42:31.513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-29 19:35:55.850</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.362819</td>\n",
       "      <td>2.405579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2018-05-04 11:04:09.610</td>\n",
       "      <td>2010-11-18 20:43:28.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-04 11:04:09.610</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.492914</td>\n",
       "      <td>-0.090201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-05-23 20:32:12.107</td>\n",
       "      <td>2010-11-18 20:43:59.693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-10 07:29:49.297</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.696061</td>\n",
       "      <td>2.830864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2018-04-29 19:26:50.553</td>\n",
       "      <td>2010-11-18 20:45:44.067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-11-18 21:16:41.767</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.606722</td>\n",
       "      <td>3.328136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PostTypeId  AcceptedAnswerId  ParentId  AnswerCount  CommentCount  \\\n",
       "0           1              15.0       NaN         10.0             7   \n",
       "1           1              16.0       NaN          7.0             0   \n",
       "2           1              31.0       NaN          5.0             1   \n",
       "3           1               NaN       NaN          8.0             1   \n",
       "4           1              85.0       NaN         10.0             1   \n",
       "\n",
       "   FavoriteCount         LastActivityDate             CreationDate  \\\n",
       "0           19.0  2019-03-31 20:10:59.657  2010-11-18 20:40:32.857   \n",
       "1            5.0  2018-04-29 19:35:55.850  2010-11-18 20:42:31.513   \n",
       "2           10.0  2018-05-04 11:04:09.610  2010-11-18 20:43:28.903   \n",
       "3            4.0  2019-05-23 20:32:12.107  2010-11-18 20:43:59.693   \n",
       "4            6.0  2018-04-29 19:26:50.553  2010-11-18 20:45:44.067   \n",
       "\n",
       "                ClosedDate             LastEditDate  ...  fe_tenure  \\\n",
       "0  2019-09-09 15:44:30.727  2019-02-10 04:06:33.283  ...    77184.0   \n",
       "1                      NaN  2018-04-29 19:35:55.850  ...        inf   \n",
       "2                      NaN  2018-05-04 11:04:09.610  ...        inf   \n",
       "3                      NaN  2019-04-10 07:29:49.297  ...        inf   \n",
       "4                      NaN  2010-11-18 21:16:41.767  ...        inf   \n",
       "\n",
       "  fe_isclosed fe_isquestion  fe_isanswer  fe_isfavorited  fe_wasedited  \\\n",
       "0           1             1            0               1             0   \n",
       "1           0             1            0               1             0   \n",
       "2           0             1            0               1             0   \n",
       "3           0             1            0               1             0   \n",
       "4           0             1            0               1             0   \n",
       "\n",
       "   fe_question_answered  umap_x_Title  umap_y_Title  kmeans_cluster_Title  \n",
       "0                     1      9.863544      2.543220                     0  \n",
       "1                     1      6.362819      2.405579                     0  \n",
       "2                     1      9.492914     -0.090201                     0  \n",
       "3                     0      6.696061      2.830864                     0  \n",
       "4                     1      5.606722      3.328136                     1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
